# -*- coding: utf-8 -*-
"""SS_P1-3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WG_AJraYdNn-AnSzLXX6Ay2W9WrqJKGA
"""

from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,ConfusionMatrixDisplay,precision_score,recall_score
import matplotlib.pyplot as plt

import json
# Opening JSON file
b = open('/content/final_benign_sample.json')
m = open('/content/final_malware_sample.json')
# returns JSON object as a dictionary
data_b = json.load(b)
data_m = json.load(m)

import pandas as pd
df_b = pd.DataFrame(columns=['apk','user_Permission','intent_category','intent_activity','service'])
df_m = pd.DataFrame(columns=['apk','user_Permission','intent_category','intent_activity','service'])

def ConvertJSONtoDF(data,df):
  L = []
  # Iterating through the json list
  for i in data:
      L.append(i)

  for j in L:
    UP,IC,IA,S = [],[],[],[]
    UPString,ICString,IAString,SString = "","","",""
    for i in data[j]['user_Permission']:
      UP.append(i)
      UPString = ','.join(UP)
    for i in data[j]['intent_category']:
      IC.append(i)
      ICString = ','.join(IC)
    for i in data[j]['intent_activity']:
      IA.append(i)
      IAString = ','.join(IA)
    for i in data[j]['service']:
      S.append(i)
      SString = ','.join(S)
    df.loc[len(df.index)] = [j,UPString,ICString,IAString,SString]

ConvertJSONtoDF(data_m, df_m)
ConvertJSONtoDF(data_b, df_b)

df_m['label'] = 1
df_b['label'] = 0

#df_m = df_m.iloc[420:]
df_b = df_b.iloc[100:]

frames = [df_b,df_m]
df = pd.concat(frames,ignore_index=True)

df.head()

from sklearn import preprocessing

cat_cols = ['apk','user_Permission','intent_category','intent_activity','service']
enc = preprocessing.LabelEncoder()

for col in cat_cols:
    df[col] = df[col].astype('str')
    df[col] = enc.fit_transform(df[col])

import numpy as np
from sklearn.model_selection import train_test_split

X = df.drop('label',axis=1)
X = df.drop(['service'],axis=1)
#'apk','intent_category','intent_activity','service'
Y = df['label']
#X_a = np.asarray(X)
#Y_a = np.asarray(Y)

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, shuffle= True)

len(X_train)

from sklearn.svm import SVC
reg_svc = SVC()
reg_svc.fit(X_train, y_train)
SVM_pred = reg_svc.predict(X_test)
print('F1 score for SVM: %0.3f' %f1_score(y_test, SVM_pred))
print("Accuracy for SVM: %0.3f" %accuracy_score(y_test, SVM_pred))
print("Precision for SVM: %0.3f" %precision_score(y_test, SVM_pred))
print("Recall for SVM: %0.3f" %recall_score(y_test, SVM_pred))

cm = confusion_matrix(y_test, SVM_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.show()

import sklearn.metrics as metrics
fpr, tpr, threshold = metrics.roc_curve(y_test, SVM_pred)
roc_auc = metrics.auc(fpr, tpr)
plt.title('Receiver Operating Characteristic for SVM')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

from sklearn.neighbors import KNeighborsClassifier
classifier = KNeighborsClassifier(n_neighbors=3)
classifier.fit(X_train, y_train)
KNN_pred = classifier.predict(X_test)
print('F1 score for KNeighborsClassifier: %0.3f' %f1_score(y_test, KNN_pred))
print("Accuracy for KNeighborsClassifier: %0.3f" %accuracy_score(y_test, KNN_pred))
print("Precision for KNeighborsClassifier: %0.3f" %precision_score(y_test, KNN_pred))
print("Recall for KNeighborsClassifier: %0.3f" %recall_score(y_test, KNN_pred))
cm = confusion_matrix(y_test, KNN_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.show()

import sklearn.metrics as metrics
fpr, tpr, threshold = metrics.roc_curve(y_test, KNN_pred)
roc_auc = metrics.auc(fpr, tpr)
plt.title('Receiver Operating Characteristic for KNN')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

from sklearn.linear_model import SGDClassifier
SGDClf = SGDClassifier(max_iter = 1000, tol=1e-3,penalty = "elasticnet")
SGDClf.fit(X_train, y_train)
SGDpred = SGDClf.predict(X_test)
print('F1 score for SGDClassifier: %0.3f' %f1_score(y_test, SGDpred))
print("Accuracy for SGDClassifier: %0.3f" %accuracy_score(y_test, SGDpred))
print("Precision for SGDClassifier: %0.3f" %precision_score(y_test, SGDpred))
print("Recall for SGDClassifier: %0.3f" %recall_score(y_test, SGDpred))
cm = confusion_matrix(y_test, SGDpred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.show()

import sklearn.metrics as metrics
fpr, tpr, threshold = metrics.roc_curve(y_test, SGDpred)
roc_auc = metrics.auc(fpr, tpr)
plt.title('Receiver Operating Characteristic for SGD')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

from sklearn.ensemble import RandomForestClassifier
clf=RandomForestClassifier(n_estimators=100)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
print('F1 score for RandomForestClassifier:', f1_score(y_test, y_pred))
cm = confusion_matrix(y_test, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.show()

from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# Scale data before applying PCA
scaling=StandardScaler()
 
# Use fit and transform method
scaling.fit(X_train)
Scaled_data=scaling.transform(X_train)
 
# Set the n_components=3
pca = PCA(n_components=2)
pca.fit(Scaled_data)
x=pca.transform(Scaled_data)
 
scaling.fit(X_test)
Scaled_data=scaling.transform(X_test)
pca.fit(Scaled_data)
x=pca.transform(Scaled_data)
from sklearn.svm import SVC
reg_svc = SVC()
reg_svc.fit(X_train, y_train)
SVM_PCA_pred = reg_svc.predict(X_test)
print("F1 score for SVM classifier after PCA feature extraction: %0.3f" %f1_score(y_test, SVM_PCA_pred))
print("Accuracy for SVM classifier after PCA feature extraction: %0.3f" %accuracy_score(y_test, SVM_PCA_pred))
print("Precision for SVM classifier after PCA feature extraction: %0.3f" %precision_score(y_test, SVM_PCA_pred))
print("Recall for SVM classifier after PCA feature extraction: %0.3f" %recall_score(y_test, SVM_PCA_pred))

cm = confusion_matrix(y_test, SVM_PCA_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.show()

import sklearn.metrics as metrics
fpr, tpr, threshold = metrics.roc_curve(y_test, SVM_PCA_pred)
roc_auc = metrics.auc(fpr, tpr)
plt.title('Receiver Operating Characteristic for SVM PCA')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

from sklearn.decomposition import FastICA

ica = FastICA(n_components=1)
X_train_ica = ica.fit_transform(X_train)
X_test_ica = ica.fit_transform(X_test)


reg_svc.fit(X_train, y_train)
SVM_ICA_pred = reg_svc.predict(X_test)

print("F1 score for SVM classifier after ICA feature extraction: %0.3f" %f1_score(y_test, SVM_ICA_pred))
print("Accuracy for SVM classifier after ICA feature extraction: %0.3f" %accuracy_score(y_test, SVM_ICA_pred))
print("Precision for SVM classifier after ICA feature extraction: %0.3f" %precision_score(y_test, SVM_ICA_pred))
print("Recall for SVM classifier after ICA feature extraction: %0.3f" %recall_score(y_test, SVM_ICA_pred))

cm = confusion_matrix(y_test, SVM_ICA_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.show()

import sklearn.metrics as metrics
fpr, tpr, threshold = metrics.roc_curve(y_test, SVM_ICA_pred)
roc_auc = metrics.auc(fpr, tpr)
plt.title('Receiver Operating Characteristic for SVM_ICA')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
lda = LinearDiscriminantAnalysis(n_components=1)
# run an LDA and use it to transform the features
X_train_lda = lda.fit(X_train, y_train).transform(X_train)
X_test_lda = lda.fit(X_test, y_test).transform(X_test)
reg_svc.fit(X_train_ica, y_train)
SVM_LDA_pred = reg_svc.predict(X_test_lda)
print("F1 score for SVM classifier after LDA feature extraction: %0.3f" %f1_score(y_test, SVM_LDA_pred))
print("Accuracy for SVM classifier after LDA feature extraction: %0.3f" %accuracy_score(y_test, SVM_LDA_pred))
print("Precision for SVM classifier after LDA feature extraction: %0.3f" %precision_score(y_test, SVM_LDA_pred))
print("Recall for SVM classifier after LDA feature extraction: %0.3f" %recall_score(y_test, SVM_LDA_pred))

cm = confusion_matrix(y_test, SVM_LDA_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()
plt.show()

import sklearn.metrics as metrics
fpr, tpr, threshold = metrics.roc_curve(y_test, SVM_LDA_pred)
roc_auc = metrics.auc(fpr, tpr)
plt.title('Receiver Operating Characteristic for SVM_LDA')
plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()